## 프랫 파싱

### 표현식 AST

표현식문: 표현식 1개로만 구성되는 명령문. wrapper 역할만 수행. 스크립트 언어들에서 대체로 지원.

```c
let x = 5; // let문
x + 10; // 표현식문
```

```go
// 표현식을 감싸는 명령문
type ExpressionStatement struct {
	Token      token.Token // the first token of the expression
	Expression Expression
}

func (es *ExpressionStatement) statementNode() {}
func (es *ExpressionStatement) TokenLiteral() string {
  return es.Token.Literal
}
func (es *ExpressionStatement) String() string {
	if es.Expression != nil {
		return es.Expression.String()
	}
	return ""
}
```

String 메서드 테스트

```go
package ast

import (
	"monkey/token"
	"testing"
)

func TestString(t *testing.T) {
	program := &Program{
		Statements: []Statement{
			&LetStatement{
				Token: token.Token{Type: token.LET, Literal: "let"},
				Name: &Identifier{
					Token: token.Token{Type: token.IDENT, Literal: "myVar"},
					Value: "myVar",
				},
				Value: &Identifier{
					Token: token.Token{Type: token.IDENT, Literal: "anotherVar"},
					Value: "anotherVar",
				},
			},
		},
	}

	if program.String() != "let myVar = anotherVar;" {
		t.Errorf("program.String() wrong. got=%q", program.String())
	}
}
```

### 프랫 파서 구현하기

**프랫 파싱(Pratt Parsing; 하향식 연산자 우선순위 파싱)**은 본 프랫의 논문 <하향식 연산자 우선순위(Top Down Operator Precedence)>에 기반을 둠.

- 프랫 파싱의 핵심은 BNF/EBNF에서 정의하는 문법 규칙과 함수(parseLetStatement)를 대응시키는 것이 아니라, **토큰 타입과 파싱 함수(semantic code)를 연관시키는 것**.

1. 파서가 토큰 타입을 만날 때마다 파싱 함수가 적절한 표현식을 파싱하고, 그 표현식을 나타내는 AST 노드를 하나 반환함.
2. 각 토큰 타입은 전위 연산자인지 중위 연산자인지에 따라 최대 2개의 파싱 함수와 연관될 수 있음.

- 전위 파싱 함수(prefix parsing function)
- 중위 파싱 함수(infix parsing function): 매개변수로 해당 중위 연산자의 좌측에 오는 Expression을 받아야 함.

```go
type (
	prefixParseFn func() ast.Expression
	infixParseFn  func(ast.Expression) ast.Expression
)
```

```go
type Parser struct {
	l      *lexer.Lexer
	errors []string

	curToken  token.Token
	peekToken token.Token

  // 토큰 타입에 맞는 prefixParseFn 혹은 infixParseFn을 선택하기 위해 필요
	prefixParseFns map[token.TokenType]prefixParseFn
	infixParseFns  map[token.TokenType]infixParseFn
}
```

```go
func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
	p.prefixParseFns[tokenType] = fn
}

func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
	p.infixParseFns[tokenType] = fn
}

func New(l *lexer.Lexer) *Parser {
	p := &Parser{
		l:      l,
		errors: []string{},
	}

	p.prefixParseFns = make(map[token.TokenType]prefixParseFn)
	p.registerPrefix(token.IDENT, p.parseIdentifier)
	p.registerPrefix(token.INT, p.parseIntegerLiteral)
	p.registerPrefix(token.BANG, p.parsePrefixExpression)
	p.registerPrefix(token.MINUS, p.parsePrefixExpression)
	p.registerPrefix(token.TRUE, p.parseBoolean)
	p.registerPrefix(token.FALSE, p.parseBoolean)
	p.registerPrefix(token.LPAREN, p.parseGroupedExpression)
	p.registerPrefix(token.IF, p.parseIfExpression)
	p.registerPrefix(token.FUNCTION, p.parseFunctionLiteral)

	p.infixParseFns = make(map[token.TokenType]infixParseFn)
	p.registerInfix(token.PLUS, p.parseInfixExpression)
	p.registerInfix(token.MINUS, p.parseInfixExpression)
	p.registerInfix(token.SLASH, p.parseInfixExpression)
	p.registerInfix(token.ASTERISK, p.parseInfixExpression)
	p.registerInfix(token.EQ, p.parseInfixExpression)
	p.registerInfix(token.NOT_EQ, p.parseInfixExpression)
	p.registerInfix(token.LT, p.parseInfixExpression)
	p.registerInfix(token.GT, p.parseInfixExpression)

	p.registerInfix(token.LPAREN, p.parseCallExpression)

	// Read two tokens, so curToken and peekToken are both set
	p.nextToken()
	p.nextToken()

	return p
}
```
